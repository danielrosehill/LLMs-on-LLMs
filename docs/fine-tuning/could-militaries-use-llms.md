# Militaries commonly conduct war-gaming. Have there been any efforts to use LLMs for this purpose?

## Generation Details

| Date       | LLM        | Access Method |
|------------|------------|---------------|
| Nov 2024 | ![GPT-4](https://img.shields.io/badge/GPT--4-412991?style=for-the-badge&logo=openai&logoColor=white) |  Web UI |

---

Based on the search results, there are two notable developments in LLMs for geopolitical and military simulations:

## Snow Globe

Snow Globe is an open-source implementation that enables automated play of qualitative wargames and geopolitical simulations\[1].

**Key Features:**

- Uses locally-run LLMs compatible with llama.cpp or Hugging Face transformers
- Best performance achieved with Mistral-7B-OpenOrca-GGUF model for local deployment\[1]
- Supports political-military wargames and AI incident response simulations\[3]
- Allows for human-AI hybrid gameplay where players can interact alongside AI agents\[3]

## PoliTune

PoliTune is a fine-tuning methodology specifically designed for aligning LLMs with political and economic ideologies\[2].

**Technical Details:**

- Works with open-source models like Llama3-8B and Mistral-7B
- Uses Parameter-Efficient Fine-Tuning (PEFT) techniques
- Requires only modification of a small subset of parameters\[2]
- Includes dataset selection and annotation frameworks for ideological alignment\[2]

## Implementation

To use Snow Globe locally:

```bash
# CPU-only installation
pip install llm-snowglobe

# GPU-supported installation
CMAKE_ARGS="-DGGML_CUDA=on" pip install llm-snowglobe
```

You can then run geopolitical crisis simulations using:

````bash
snowglobe_server &
examples/ac.py --human 1
```

---
*The above text was generated by a large language model (LLM) and its accuracy has not been validated. This page is part of 'LLMs-on-LLMs,' a Github repository by Daniel Rosehill which explores how curious humans can use LLMs to better their understanding of LLMs and AI. However, the information should not be regarded as authoritative and given the fast pace of evolution in LLM technology will eventually become deprecated. This footer was added at 16-Nov-2024.*
